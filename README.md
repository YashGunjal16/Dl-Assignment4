# ğŸ§  NLP Preprocessing & Text Classification

---

## ğŸ¯ Objective
Implement NLP preprocessing techniques and build a text classification model using machine learning on the SMS Spam Collection dataset.

---

## âœ… Learning Outcomes
- Understand and apply NLP preprocessing (tokenization, stopword removal, stemming, lemmatization)
- Use text vectorization techniques (TF-IDF, CountVectorizer)
- Build and evaluate a machine learning classification model
- Measure performance using standard evaluation metrics

---

## ğŸ—‚ï¸ Dataset
- **Name**: SMS Spam Collection
- **Source**: [Best Datasets for Text Classification](https://en.innovatiana.com/post/best-datasets-for-text-classification)

---

## ğŸ› ï¸ Steps & Tools

### ğŸ”¹ Step 1: Import Libraries
- `pandas`, `numpy`, `matplotlib`, `seaborn`
- `nltk`, `spaCy`
- `scikit-learn`

### ğŸ”¹ Step 2: Load Dataset
- Read TSV file into DataFrame
- Inspect data and label distribution

### ğŸ”¹ Step 3: NLP Preprocessing
- Lowercasing
- Remove non-alphabetic characters
- Tokenization (`spaCy`)
- Stopword removal (`nltk`)
- Stemming (`PorterStemmer`)
- Lemmatization (`spaCy`)

### ğŸ”¹ Step 4: Vectorization
- `CountVectorizer`
- `TfidfVectorizer`

### ğŸ”¹ Step 5: Model Building
- **Algorithm**: Logistic Regression
- **Split**: 80% train / 20% test

### ğŸ”¹ Step 6: Evaluation
- Accuracy, Precision, Recall, F1 Score
- Confusion Matrix
- Classification Report

---

## ğŸ“Š Results

| Metric     | Score     |
|------------|-----------|
| Accuracy   | 0.9764    |
| Precision  | 0.9591    |
| Recall     | 0.9487    |
| F1 Score   | 0.9539    |

---

## ğŸ’¡ Conclusion
- Logistic Regression showed high performance for spam detection.
- Proper preprocessing and vectorization significantly improved results.
- Minimal misclassification observed.

---

## ğŸ”® Future Work
- Explore SVM, NaÃ¯ve Bayes, and deep learning models (e.g., BERT)
- Apply to multi-class datasets
- Deploy in real-time systems

---
